{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only necessary if you're running Python 2.7 or lower\n",
    "from __future__ import print_function, division\n",
    "from six.moves import range\n",
    "\n",
    "# import matplotlib and define our alias\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot figures within the notebook rather than externally\n",
    "%matplotlib inline\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# scipy \n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "We are now going to be taking the skills we learned in Part 2 and applying them to do some data analysis using **linear regression**. Although linear regression appears simple at first glance, it actually has a surprising amount of depth and is applicable in a bunch of different domains. Most importantly, it provides an accessible way to get a handle on several big concepts in data analysis (and especially model fitting) and provides an excellent intro to using Python to do science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In honor of the world cup happening this year (right now!), we are going to be analyzing data from the 2014 World Cup! Everything is taken from https://github.com/openfootball/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in JSON\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in our data\n",
    "filename = 'worldcup_2014.json'\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    cup_data = json.load(f)  # world cup JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what's in our dictionary\n",
    "cup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the relevant keys\n",
    "cup_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check group-level data\n",
    "cup_data['rounds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our starting goal here is going to be pretty simple: **try to determine a simple linear relationship between the number of goals scored and total number of games played.** In other words, we want a model like\n",
    "\n",
    "$$ y = ax + b $$\n",
    "\n",
    "where $y$ is the number of games played, $x$ is the number of goals scored, and $a$ and $b$ are coefficients of the fit. We are using the number of games played as a proxy for ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to figure out how many goals were scored during the group stages for each team. We are going to compute the \"effective\" number of goals by taking the difference between the number of goals scored \"for\" the team $x_{\\rm for}$ and the number scored \"against\" $x_{\\rm against}$:\n",
    "\n",
    "$$ x = x_{\\rm for} - x_{\\rm against} $$\n",
    "\n",
    "\n",
    "Let's create a dictionary for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "\n",
    "# read out world cup 2014 data from the dictionary\n",
    "for matchup in cup_data['rounds']:\n",
    "    for match in matchup['matches']:\n",
    "        team1, team2 = match['team1']['name'], match['team2']['name']  # team names\n",
    "        score1, score2 = match['score1'], match['score2']  # scores\n",
    "        score = score1 - score2  # effective score\n",
    "        try:\n",
    "            data[team1]['goals'] += score\n",
    "            data[team2]['goals'] -= score\n",
    "            data[team1]['games'] += 1\n",
    "            data[team2]['games'] += 1\n",
    "        except:\n",
    "            data[team1] = {'goals': score, 'games': 1}\n",
    "            data[team2] = {'goals': -score, 'games': 1}\n",
    "        if matchup['name'] == 'Match for third place':\n",
    "            data[team1]['games'] -= 1\n",
    "            data[team2]['games'] -= 1\n",
    "\n",
    "# Check data.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is in an accessible format, let's try and get it into something we can do math with.  **Copy over the data from our dictionary into `numpy` arrays called `x` and `y`. Then plot the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy over our data into x and y\n",
    "x = ...\n",
    "y = ...\n",
    "\n",
    "# plot our results\n",
    "# remember to label your axes!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra challenge: If you aren't already, plot with data points instead of lines.**\n",
    "\n",
    "**Extra challenge: See if you can plot a line that fits the data reasonably well by just \"eyeballing it\". Try changing the options to see if you can distinguish which slopes/intercepts appear to fit the data well and which don't.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absence of known errors, the way to solve this problem is to define an appropriate **loss function** $L(\\boldsymbol{\\Theta} \\,|\\, \\mathbf{D})$ that we hope to minimize, where $\\boldsymbol{\\Theta}$ contains all the parameters of interest (here $a$ and $b$) and $\\mathbf{D}$ contains all our data. Defining $\\mathbf{x} \\equiv \\lbrace x_1, \\dots, x_n \\rbrace$ and $\\mathbf{y} \\equiv \\lbrace y_1, \\dots, y_n \\rbrace$, let's write our loss function as the sum of the *squares* of the **residuals**\n",
    "\n",
    "$$ L(\\alpha, \\beta \\,|\\, \\mathbf{x}, \\mathbf{y}) = \\sum_{i=1}^{n} \\left( \\Delta y_i \\right)^2 \\equiv \\sum_{i=1}^{n} \\left( y(x) - y_i \\right)^2 = \\sum_{i=1}^{n} \\left( \\alpha + \\beta x_i - y_i \\right)^2 \\quad . $$\n",
    "\n",
    "**Let's define our linear relationship and loss function below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear fit (takes input *vector* `theta` -> (a,b))\n",
    "def linear(theta):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss(theta):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test out a few lines and see what the loss function is. Combined with the plot above, see if you can get a reasonable fit to the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing out the linear fit and loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Best-Fit Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best-fit line ($a$ and $b$) is the one that minimizes our loss function. To compute this, we need to locate the [critical points](https://en.wikipedia.org/wiki/Critical_point) where\n",
    "\n",
    "$$ \\frac{\\partial f(\\boldsymbol{\\Theta})}{\\partial \\Theta_i} = 0 $$\n",
    "\n",
    "for all parameters $\\Theta_i$ of interest within $\\boldsymbol{\\Theta}$. In our case, we get:\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial \\alpha} = \\sum_{i=1}^{n} 2(\\alpha + \\beta x_i - y_i) = 0 $$\n",
    "$$ \\frac{\\partial L}{\\partial \\beta} = \\sum_{i=1}^{n} 2\\beta(\\alpha + \\beta x_i - y_i) = 0 $$\n",
    "\n",
    "This gives us two linear equations with two unknowns, which we can solve *exactly* using linear algebra to get an analytic best-fit solution $\\hat{\\alpha}$ and $\\hat{\\beta}$. You're welcome to try and solve this explicitly now; we'll come back to this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# space if you want to try your hand at solving the linear system explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we'll minimize our loss function using the `minimize` package contained within **`scipy.optimize`**. **Using the [documentation](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.optimize.minimize.html), see if you can figure out how to use `minimize` to get the best-fit parameters `theta` based on our loss function `loss`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize the loss function\n",
    "results = minimize(...)\n",
    "theta_best = ...\n",
    "\n",
    "# Print out results\n",
    "print(results)\n",
    "print('Best-Fit:', theta_best)\n",
    "\n",
    "# Plot comparison between data and results\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra challenge: Spend some time digging around to see if you can understand both how the output is stored (as a [`dict`](https://docs.python.org/3/tutorial/datastructures.html#dictionaries)) and what some of the terms mean. We'll get back to these quantities in more detail later.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Gaussian Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a best-fit result. But how reliable is it? How well do we really know what the relationship is between goals scored and final placement? To figure this out, we need to know the overall **errors** are on our result. Let's explore that a bit now starting with our best-fit result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common approximation is to assume our error are Gaussian centered around the best fit $\\boldsymbol{\\Theta}_{\\rm best}$ with a covariance matrix\n",
    "\n",
    "$$ \n",
    "\\mathbf{C} = \n",
    "\\begin{bmatrix}\n",
    "\\sigma_x^2 & \\rho \\sigma_x \\sigma_y \\\\\n",
    "\\rho \\sigma_x \\sigma_y & \\sigma_y^2 \\\\\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "This is reported above in the `hess_inv` option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the covariance matrix from `hess_inv`, generate `Nmc=10000` random realizations of the slope $a$ and intercept $b$ using `numpy.random.multivariate_normal`. Then plot the results as a 2-D histogram with `Nbins=20` bins.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmc, Nbins = 10000, 20\n",
    "\n",
    "# Draw random samples around best-fit given errors.\n",
    "thetas = ...\n",
    "\n",
    "# Plot draws as 2-D histogram.\n",
    "# Remember to label your axes!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge: Add in a labeled colorbar and change the colormap so that the scale goes from white to gray.** \n",
    "\n",
    "**Extra challenge: Using the outputs from `hist2d`, find the location of the bin with the most counts.**\n",
    "\n",
    "**Extra challenge: Plot 100 realizations of the predicted line/values over the data points from above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful, but doesn't give us everything we're looking for. We want to know, e.g., how many goals it takes to get to the finals. That's going to require us to take our $\\boldsymbol{\\Theta}$ values and transform them into a concrete number of goals needed to get to round 7 (the finals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to convert from theta to goals for a given round\n",
    "# i.e., compute x from y=ax+b for y,a,b given\n",
    "def goals_needed(theta, matchup):  # we're avoiding \"round\" since it's special\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using your function, compute the number of goals needed to get to the finals and plot the distribution of the results as a histogram using `plt.hist` with `Nbins=50` bins.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute goals needed\n",
    "final_preds = ...\n",
    "\n",
    "# plot histogram of results\n",
    "# Remember to label your axes!\n",
    "Nbins = 50\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge: Change the histogram color and style so that you only plot a black outline with no color fill.**\n",
    "\n",
    "**Extra challenge: See how the distribution changes for each round, starting from round 4 (the first elimination round at the end of the group stages.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, we might not fully trust our data or the errors reported from our fit. This can happen for any number of reasons, but often is the case if the fit appears to be sensitive to a few \"special\" data points. Instead, we can try to estimate the errors using **bootstrap resampling**.\n",
    "\n",
    "Essentially, the idea is to pretend we observed the data again and re-fit our line. We obviously can't do that, so we approximate it by drawing a new set of data points from our original set of data points, where the probability of selecting any particular data point out of $N$ data points is $p = 1/N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this numerically in Python using the `numpy.random.choice` function. **Using the example below, create a function that returns a new set of `x_resamp` and `y_resamp` values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create example data\n",
    "N_example = 10  # number of data points\n",
    "x_example = np.arange(N_example)  # x grid\n",
    "y_example = np.arange(N_example) * 5  # y grid\n",
    "print('Original data:')\n",
    "print(x_example)\n",
    "print(y_example)\n",
    "\n",
    "# resample data\n",
    "idxs = np.random.choice(N_example, size=N_example)  # resample `N_example` indices\n",
    "x_example_r = x_example[idxs]  # select resampled x values\n",
    "y_example_r = y_example[idxs]  # select resampled y values\n",
    "print('\\nResampled data:')\n",
    "print(idxs)\n",
    "print(x_example_r)\n",
    "print(y_example_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define resampling function\n",
    "def resample_data(x, y):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, using the code from earlier and a `for` loop, resample the data and recompute the best-fit line `Nmc=10000` times.**\n",
    "\n",
    "**NOTE THAT YOU WILL PROBABLY NEED TO REDEFINE YOUR FITTING FUNCTIONS FROM EARLIER TO WORK WITH THIS RESAMPLED DATA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# redefine linear fit if necessary\n",
    "def linear_resamp(theta):\n",
    "    ...\n",
    "\n",
    "# redefine loss function if necessary\n",
    "def loss_resamp(theta):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmc, Nbins = 10000, 20\n",
    "\n",
    "# resample data and re-fit line\n",
    "thetas_resamp = ...\n",
    "for i in range(Nmc):\n",
    "    x_resamp, y_resamp = resample_data(x, y)  # resample data\n",
    "    results = minimize(...)  # minimize resample data\n",
    "    ...  # assign value to thetas_resamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once you're done, plot the data as a 2-D histogram as before.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot draws as 2-D histogram.\n",
    "# Remember to label your axes!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, re-compute the number of goals needed to get to the finals for these new $\\boldsymbol{\\Theta}$ samples and plot the distribution of the results as a histogram using `plt.hist` with `Nbins=50` bins.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute goals needed\n",
    "final_preds_resamp = ...\n",
    "\n",
    "# plot histogram of results\n",
    "# Remember to label your axes!\n",
    "Nbins = 50\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra challenge: See if you can directly compare the (1) 2-D histograms, (2) the 1-D histograms for the number of goals needed to go to the finals, and (3) the predicted lines for both cases.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover this material if we have extra time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ironically, sometimes the best method for determining the errors is the most straightforward: just find out how good your fit is over a bunch of combinations of $a$ and $b$. More formally, over a grid in $a$ and $b$ you compute\n",
    "\n",
    "$$ w(a, b) = \\exp[-L(a,b)/2] $$\n",
    "\n",
    "where $L(a,b)$ is the loss function from before and $w(a,b)$ is the relative weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on your results from above, define a grid of `Nx=250` points for $a$ around the best fit and a grid of `Ny=250` points for $b$ around the best fit. Then, compute the loss and relative weight for every $(a,b)$ combination in the grid.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grids\n",
    "a_grid = ...\n",
    "b_grid = ...\n",
    "\n",
    "# compute losses over grids\n",
    "...\n",
    "\n",
    "# compute weights\n",
    "weights = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the _weighted_ 2-D histogram of the fits and the _weighted_ 1-D histogram of the goals needed to get to the finals.** Note that `meshgrid` might be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nbins = 20\n",
    "\n",
    "# Plot draws as 2-D histogram.\n",
    "# Remember to label your axes!\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute goals needed\n",
    "final_preds_grid = ...\n",
    "final_preds_weights = ...\n",
    "\n",
    "# plot histogram of results\n",
    "# Remember to label your axes!\n",
    "Nbins = 50\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
